{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "import seaborn as sns\n",
    "from pytfa.io.json import load_json_model\n",
    "from skimpy.analysis.oracle import *\n",
    "import os\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "from utils.remove_outliers import remove_outliers_parallel\n",
    "\n",
    "import configparser\n",
    "\n",
    "# Load config.ini\n",
    "config = configparser.ConfigParser()\n",
    "config.read(os.path.abspath(os.path.join('..', 'src', 'config.ini')))\n",
    "\n",
    "base_dir = config['paths']['base_dir']\n",
    "path_to_samples_WT = os.path.join(base_dir, config['paths']['path_to_samples_WT'])\n",
    "path_to_samples_MUT = os.path.join(base_dir, config['paths']['path_to_samples_MUT'])\n",
    "\n",
    "path_to_tmodel_WT = os.path.join(base_dir, config['paths']['path_to_tmodel_WT'])\n",
    "path_to_tmodel_MUT = os.path.join(base_dir, config['paths']['path_to_tmodel_MUT'])\n",
    "\n",
    "path_to_fcc_WT = os.path.join(base_dir, config['paths']['path_to_fcc_WT'])\n",
    "path_to_fcc_MUT = os.path.join(base_dir, config['paths']['path_to_fcc_MUT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wt = load_json_model(path_to_tmodel_WT)\n",
    "model_mut = load_json_model(path_to_tmodel_MUT)\n",
    "rxns_wt = [rxn.id for rxn in model_wt.reactions]\n",
    "rxns_mut = [rxn.id for rxn in model_mut.reactions]\n",
    "\n",
    "# Find which reactions are in mut but not in wt\n",
    "rxns_diff = list(set(rxns_mut) - set(rxns_wt))\n",
    "print('Reactions in mut but not in wt:', rxns_diff)\n",
    "\n",
    "# Find which reactions have opposite directionality in mut comprade to wt\n",
    "diff_bdrs = []\n",
    "for rxn in model_wt.reactions:\n",
    "    try:\n",
    "        rxn_mut = model_mut.reactions.get_by_id(rxn.id)\n",
    "        if rxn_mut.lower_bound*rxn.lower_bound < 0:\n",
    "            print(rxn.id)\n",
    "            diff_bdrs.append(rxn.id)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "print(len(diff_bdrs), 'reactions have opposite directionality in mut compared to wt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 5000 steady state samples for each model\n",
    "samples_WT = pd.read_csv(path_to_samples_WT, index_col=0, header=0)\n",
    "samples_MUT = pd.read_csv(path_to_samples_MUT, index_col=0, header=0)\n",
    "\n",
    "# Remove unwanted columns\n",
    "prefix_list = ['DG_', 'DGo_', 'FU_', 'BU_', 'MinFluxVar_', 'LnGamma_', 'LC_']\n",
    "samples_WT = samples_WT[samples_WT.columns[~samples_WT.columns.str.startswith(tuple(prefix_list))]]\n",
    "samples_MUT = samples_MUT[samples_MUT.columns[~samples_MUT.columns.str.startswith(tuple(prefix_list))]]\n",
    "\n",
    "# Remove columns if all the rows are NaN\n",
    "samples_WT = samples_WT.dropna(axis=1, how='all')\n",
    "samples_MUT = samples_MUT.dropna(axis=1, how='all')\n",
    "\n",
    "# Compare the steady states that were used for the MCA analysis\n",
    "mut_ss = []\n",
    "for file in os.listdir(path_to_fcc_MUT):\n",
    "    try:\n",
    "        mut_ss.append(int(file.split('_')[4]))\n",
    "    except:\n",
    "        print('The file', file, 'does not follow the naming convention')\n",
    "\n",
    "mut_ss = np.unique(mut_ss)\n",
    "samples_MUT = samples_MUT.loc[mut_ss,:]\n",
    "\n",
    "# Find the steady states that were used for the MCA res\n",
    "wt_ss = []\n",
    "for file in os.listdir(path_to_fcc_WT):\n",
    "    try:\n",
    "        wt_ss.append(int(file.split('_')[4]))\n",
    "    except:\n",
    "        print('The file', file, 'does not follow the naming convention')\n",
    "\n",
    "wt_ss = np.unique(wt_ss)\n",
    "samples_WT = samples_WT.loc[wt_ss,:]\n",
    "\n",
    "# Keep only the common columns in the two sample dataframes\n",
    "common_cols = list(set(samples_WT.columns).intersection(samples_MUT.columns))\n",
    "samples_WT = samples_WT[common_cols]\n",
    "samples_MUT = samples_MUT[common_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute L2 norm for a single pair\n",
    "def compute_diff(args):\n",
    "    i, j = args\n",
    "    diff = samples_WT.loc[i] - samples_MUT.loc[j]\n",
    "    # Make the pair into a string \n",
    "    pair = str(i) + '_' + str(j)\n",
    "    return pair, np.linalg.norm(diff)\n",
    "\n",
    "# Main parallelized computation\n",
    "if __name__ == \"__main__\":\n",
    "    # Create all combinations of indices for WT and MUT\n",
    "    wt_indices = samples_WT.index\n",
    "    mut_indices = samples_MUT.index\n",
    "    all_pairs = [(i, j) for i in wt_indices for j in mut_indices]\n",
    "\n",
    "    # Set up multiprocessing pool\n",
    "    with Pool(processes=15) as pool:\n",
    "        # Map the function to the list of pairs\n",
    "        results = list(tqdm(pool.imap(compute_diff, all_pairs), total=len(all_pairs)))\n",
    "\n",
    "    # Convert results to a dictionary\n",
    "    diffs = dict(results)\n",
    "\n",
    "    # Make a dataframe from the dictionary\n",
    "    diff_df = pd.DataFrame.from_dict(diffs, orient='index', columns=['L2_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_l2_norm = diff_df['L2_norm'].mean()\n",
    "std_l2_norm = diff_df['L2_norm'].std()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(diff_df.L2_norm, kde=True, bins=30, color='skyblue', legend=False)\n",
    "plt.axvline(mean_l2_norm, color='red', linestyle='dashed', linewidth=2, label='Mean')\n",
    "plt.axvline(mean_l2_norm + std_l2_norm, color='green', linestyle='dashed', linewidth=2, label='Mean + 1 Std')\n",
    "plt.axvline(mean_l2_norm - std_l2_norm, color='green', linestyle='dashed', linewidth=2, label='Mean - 1 Std')\n",
    "plt.title('Distribution of L2 Norm Differences', fontsize=18)\n",
    "plt.xlabel('L2 Norm', fontsize=15)\n",
    "plt.ylabel('Number of pairs', fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which pair is closest to the average difference\n",
    "mean = diff_df['L2_norm'].mean()\n",
    "diff_df['diff_from_mean'] = abs(diff_df['L2_norm'] - mean)\n",
    "print(diff_df['diff_from_mean'].idxmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_l2_norm = diff_df['L2_norm'].mean()\n",
    "std_l2_norm = diff_df['L2_norm'].std()\n",
    "median_l2_norm = diff_df['L2_norm'].median()\n",
    "\n",
    "print(f\"Mean L2 Norm: {mean_l2_norm}\")\n",
    "print(f\"Standard Deviation of L2 Norm: {std_l2_norm}\")\n",
    "print(f\"Median L2 Norm: {median_l2_norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df.sort_values(by='diff_from_mean')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
