{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimpy.analysis.oracle import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append(\"../../../../NRAplus/NRAplus\") # Adds higher directory to python modules path.\n",
    "sys.path.append('../')\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import kaleido\n",
    "\n",
    "from utils.nra_save_custom_json import load_json_nra_model\n",
    "from pytfa.io.json import load_json_model\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(os.path.abspath('../src/config.ini'))\n",
    "base_dir = config['paths']['base_dir']\n",
    "path_to_tfa_samples_MUT = os.path.join(base_dir, config['paths']['path_to_samples_MUT'])\n",
    "path_to_tfa_samples_WT = os.path.join(base_dir, config['paths']['path_to_samples_WT'])\n",
    "path_to_tmodel_MUT = os.path.join(base_dir, config['paths']['path_to_tmodel_MUT'])\n",
    "path_to_tmodel_WT = os.path.join(base_dir, config['paths']['path_to_tmodel_WT'])\n",
    "path_to_nra_model = os.path.join(base_dir, config['paths']['path_to_nra_model'])\n",
    "path_to_solutions = os.path.join(base_dir, config['paths']['path_to_solutions'])\n",
    "path_to_essential_enzymes = os.path.join(base_dir, config['paths']['path_to_essential_enzymes'])\n",
    "path_to_tflink_database = os.path.join(base_dir, config['paths']['path_to_tflink_database'])\n",
    "path_to_recon_model = os.path.join(base_dir, config['paths']['path_to_recon_model'])\n",
    "path_to_gene_to_uniprot_mapping = os.path.join(base_dir, config['paths']['path_to_gene_to_uniprot_mapping'])\n",
    "path_to_essential_enzymes_to_TFs_mapping = os.path.join(base_dir, config['paths']['path_to_essential_enzymes_to_TFs_mapping'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nra_model = load_json_nra_model(path_to_nra_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Figure S9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all the objective function values\n",
    "obj_values = pd.DataFrame(columns=['enzymes_perturbed', 'obj_value'])\n",
    "for max_enz_mod in [1, 2, 5, 10, 50, 100, 150, 200, 250, 500, 877]:\n",
    "    # Load the solution\n",
    "    sol = pd.read_csv(path_to_solutions.format(max_enz_mod), index_col=0)\n",
    "    # Get the values of the auxilariy variables \n",
    "    aux_vars = [v for v in sol.index if v.startswith('AUXV_')]\n",
    "    # Get the value of the objective function by adding the values of the auxiliary variables\n",
    "    obj_value = sol.loc[aux_vars].sum().values[0]\n",
    "    obj_values.loc[max_enz_mod] = obj_value\n",
    "\n",
    "    # Find how many enzymes were perturbed\n",
    "    epsilon = 1e-9\n",
    "    active_enzyme_regulations = [v for v in sol.index if v.startswith('EU_') or v.startswith('ED_')]\n",
    "    active_enzyme_regulations = [v for v in active_enzyme_regulations\n",
    "                                    if np.abs(sol.loc[v].values[0]) > epsilon]\n",
    "    print('Number of enzymes perturbed:', len(active_enzyme_regulations))\n",
    "    print('Objective value:', obj_value, '\\n')\n",
    "\n",
    "    obj_values.loc[max_enz_mod] = [len(active_enzyme_regulations), obj_value]\n",
    "\n",
    "original_value = 371.2092331511442"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the main curve\n",
    "plt.plot(\n",
    "    obj_values.enzymes_perturbed,\n",
    "    obj_values.obj_value,\n",
    "    marker='o',\n",
    "    color='steelblue',\n",
    "    linewidth=2,\n",
    "    markersize=6,\n",
    "    label='Difference after enzyme changes'\n",
    ")\n",
    "\n",
    "# Add the reference (original value)\n",
    "plt.axhline(\n",
    "    original_value,\n",
    "    color='firebrick',\n",
    "    linestyle='--',\n",
    "    linewidth=2,\n",
    "    label='Original Difference (no changes)'\n",
    ")\n",
    "\n",
    "# Labels for a biology audience\n",
    "plt.xlabel('Number of enzyme activity changes', fontsize=16)\n",
    "plt.ylabel('Difference in metabolic activity', fontsize=16)\n",
    "\n",
    "# Axis styling\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Legend\n",
    "plt.legend(fontsize=14, frameon=False, loc='center right')\n",
    "\n",
    "# Clean aesthetics\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Figure 5A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the solution with 5 enzyme modifications\n",
    "sol =  pd.read_csv(path_to_solutions.format(250), index_col=0)\n",
    "\n",
    "# Identify the AUXV variables\n",
    "aux_vars = [var for var in sol.index if var.startswith('AUXV_')]\n",
    "modifications = [0, 100, 250, 877]\n",
    "auxv_df = pd.DataFrame(index=aux_vars, columns=modifications)\n",
    "for max_enz_mod in modifications:\n",
    "    sol =  pd.read_csv(path_to_solutions.format(max_enz_mod), index_col=0)\n",
    "\n",
    "    # Add to auxv_df DataFrame\n",
    "    auxv_df[max_enz_mod] = sol.loc[aux_vars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort auxvars per subsystem and find total subsystem deviations per solution\n",
    "core_ss = ['Glycolysis/gluconeogenesis', 'Citric acid cycle', 'Pentose phosphate pathway', 'Glutamate metabolism',\n",
    "'ROS detoxification', 'Glycine, serine, alanine, and threonine metabolism', 'Urea cycle', 'Arginine and proline metabolism',\n",
    "'Purine synthesis', 'Pyrimidine synthesis', 'ETC_Rxns', 'NAD metabolism']\n",
    "subs_deviations = pd.DataFrame(index=core_ss, columns=modifications).fillna(0)\n",
    "\n",
    "\n",
    "for var in aux_vars:\n",
    "    rxn = var.split('AUXV_',1)[1]\n",
    "    rxn = nra_model.reactions.get_by_id(rxn)\n",
    "    if rxn.subsystem in core_ss:\n",
    "        for max_enz_mod in modifications:\n",
    "            subs_deviations.loc[rxn.subsystem, max_enz_mod] += auxv_df.loc[var, max_enz_mod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Choose a nice color palette (e.g., Set2)\n",
    "palette = plt.get_cmap('Set2').colors\n",
    "\n",
    "# Filter to only the desired fold-changes\n",
    "keep_mods = [0, 100, 250, 877]\n",
    "data = subs_deviations[keep_mods]\n",
    "\n",
    "# Rename index entries\n",
    "data = data.rename(index={\n",
    "    'ETC_Rxns': 'Oxidative phosphorylation',\n",
    "    'Glycine, serine, alanine, and threonine metabolism': 'Gly/Ser/Ala/Thr metabolism',\n",
    "    'Arginine and proline metabolism': 'Arg/Pro metabolism'\n",
    "})\n",
    "\n",
    "# Reorder the index to match the desired order\n",
    "order = [\n",
    "    'Gly/Ser/Ala/Thr metabolism', 'Arg/Pro metabolism', 'Glutamate metabolism',\n",
    "    'Glycolysis/gluconeogenesis', 'Pentose phosphate pathway', 'Citric acid cycle',\n",
    "    'Urea cycle', 'Pyrimidine synthesis', 'Purine synthesis',\n",
    "    'NAD metabolism', 'ROS detoxification', 'Oxidative phosphorylation'\n",
    "]\n",
    "data = data.reindex(order)\n",
    "\n",
    "# Create the bar plot\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "n_cats = len(data.index)\n",
    "n_mods = len(data.columns)\n",
    "bar_width = 0.8 / n_mods\n",
    "x = np.arange(n_cats)\n",
    "\n",
    "for i, mod in enumerate(data.columns):\n",
    "    ax.bar(\n",
    "        x + i * bar_width,\n",
    "        data[mod].values,\n",
    "        width=bar_width,\n",
    "        label=f'{mod}',\n",
    "        color=palette[i % len(palette)],\n",
    "        edgecolor='black',\n",
    "        linewidth=1\n",
    "    )\n",
    "\n",
    "# Ticks & labels\n",
    "ax.set_xticks(x + bar_width * (n_mods - 1) / 2)\n",
    "ax.set_xticklabels(data.index, rotation=45, ha='right', fontsize=12)\n",
    "ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "ax.set_xlabel('Metabolic Pathway', fontsize=16)\n",
    "ax.set_ylabel('Total pathway deviation', fontsize=16)\n",
    "\n",
    "# Remove upper and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Place legend inside and remove its frame\n",
    "legend = ax.legend(\n",
    "    title='Enzyme fold changes applied',\n",
    "    loc='upper right',\n",
    "    frameon=False,\n",
    "    fontsize=12,\n",
    "    title_fontsize=16,\n",
    ")\n",
    "\n",
    "# Left-align the legend title and content box\n",
    "legend.get_title().set_ha('left')\n",
    "legend._legend_box.align = \"left\"\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42  # For PDF\n",
    "plt.rcParams['svg.fonttype'] = 'none'  # For SVG\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Figure S10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel_MUT = load_json_model(path_to_tmodel_MUT)\n",
    "tmodel_WT = load_json_model(path_to_tmodel_WT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many reactions have opposite directionality in the two models.\n",
    "# We will not include them in the objective function.\n",
    "diff_dir_rxns = []\n",
    "mut_rxns_ids = [rxn.id for rxn  in tmodel_MUT.reactions]\n",
    "for rxn in tmodel_WT.reactions:\n",
    "    if rxn.id in mut_rxns_ids:\n",
    "        rxn_mut = tmodel_MUT.reactions.get_by_id(rxn.id)\n",
    "        if rxn_mut.lower_bound*rxn.lower_bound < 0:\n",
    "            diff_dir_rxns.append(rxn.id)\n",
    "\n",
    "print('Number of reactions with opposite directionality in the two models:', len(diff_dir_rxns))\n",
    "\n",
    "# Load the WT steady state samples and use PCA to determine which one is closest to the mean\n",
    "samples_WT = pd.read_csv(path_to_tfa_samples_WT, index_col=0)\n",
    "\n",
    "# Clean the samples to only include active fluxes and metabolite concentrations\n",
    "active_fluxes = []\n",
    "for r in tmodel_WT.reactions:\n",
    "    if r.lower_bound > 0:\n",
    "        active_fluxes.append(r.id)\n",
    "    else:\n",
    "        active_fluxes.append(r.reverse_id)\n",
    "\n",
    "active_vars = [i for i in tmodel_WT.variables.keys() if i.startswith('LC_')]\n",
    "\n",
    "samples_WT_clean = pd.DataFrame()\n",
    "for name, vals in samples_WT.iteritems():\n",
    "    if name in active_fluxes or name in active_vars:\n",
    "        samples_WT_clean[name] = vals\n",
    "        \n",
    "samples_WT_clean = samples_WT_clean.loc[0:599, :]\n",
    "\n",
    "# Select the reference sample for WT\n",
    "reference_sample_index = 66\n",
    "reference_sample_WT = samples_WT_clean.loc[reference_sample_index,:]\n",
    "\n",
    "# Load the MUT steady state samples\n",
    "tfa_ix = 17\n",
    "tfa_sample = pd.read_csv(path_to_tfa_samples_MUT, header=0, index_col=0).iloc[tfa_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many reactions have opposite directionality in the two models.\n",
    "# We will not include them in the objective function.\n",
    "diff_dir_rxns = []\n",
    "mut_rxns_ids = [rxn.id for rxn  in tmodel_MUT.reactions]\n",
    "for rxn in tmodel_WT.reactions:\n",
    "    if rxn.id in mut_rxns_ids:\n",
    "        rxn_mut = tmodel_MUT.reactions.get_by_id(rxn.id)\n",
    "        if rxn_mut.lower_bound*rxn.lower_bound < 0:\n",
    "            diff_dir_rxns.append(rxn.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all the optimization results and find the essential enzymes (always active)\n",
    "# nra_model.max_enzyme_modifications = 250\n",
    "epsilon = 1e-9\n",
    "sol = pd.read_csv(path_to_solutions.format(250), index_col=0)\n",
    "enzyme_use_vars_250 = [i for i in sol.index if i.startswith('EUDUSE_') and np.isclose(sol.loc[i][0],0)]\n",
    "enzymes_used_250 = [i.split('EUDUSE_')[1] for i in enzyme_use_vars_250]\n",
    "\n",
    "# Find all the reactions in subsystems glycokysis, oxidative phosphorylation and Fatty acid synthesis\n",
    "subsystems_of_interest = core_ss = ['Glycolysis/gluconeogenesis', 'Citric acid cycle', 'Pentose phosphate pathway', 'Glutamate metabolism',\n",
    "'ROS detoxification', 'Glycine, serine, alanine, and threonine metabolism', 'Urea cycle', 'Arginine and proline metabolism',\n",
    "'Purine synthesis', 'Pyrimidine synthesis', 'ETC_Rxns', 'NAD metabolism']\n",
    "\n",
    "df_effect = pd.DataFrame(columns=['Reaction', 'Subsystem'])\n",
    "for rxn in nra_model.reactions:\n",
    "    if rxn.subsystem in subsystems_of_interest and rxn.id not in diff_dir_rxns:\n",
    "        if 'AUXV_'+rxn.id not in sol.index:\n",
    "            print('Reaction {} is not in the solution'.format(rxn.id))\n",
    "            # continue\n",
    "        df_effect = df_effect.append({'Reaction': rxn.id, 'Subsystem': rxn.subsystem}, ignore_index=True)\n",
    "\n",
    "df_effect.set_index('Reaction', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the effect of each essential enzyme on the fluxes fo each subsystem\n",
    "for enz in tqdm(enzymes_used_250):\n",
    "    df_effect[enz] = 0.0\n",
    "    for rxn in df_effect.index:\n",
    "        # Find control coefficient of the enzyme on the reaction\n",
    "        frb = nra_model.constraints['FRB_{}'.format(rxn)]\n",
    "        fcc = - frb.get_linear_coefficients([nra_model.variables['EU_{}'.format(enz)]])[nra_model.variables['EU_{}'.format(enz)]]\n",
    "\n",
    "        # Find fcc*(EU_enz - ED_enz)\n",
    "        eu_enz = sol.loc['EU_{}'.format(enz)][0]\n",
    "        ed_enz = sol.loc['ED_{}'.format(enz)][0]\n",
    "        df_effect.loc[rxn, enz] = fcc * (eu_enz - ed_enz) \n",
    "\n",
    "# Have a column with the ratio that we remove from the objective function i.e. ln(vWT/vMUT)\n",
    "df_effect_const = pd.DataFrame(index=df_effect.index, columns=['ln_vWT_vMUT'])\n",
    "# Add a column with the subsystem of the reaction\n",
    "df_effect_const['Subsystem'] = df_effect['Subsystem']\n",
    "df_effect_const['ln_vWT_vMUT'] = 0.0\n",
    "for rxn in df_effect_const.index:\n",
    "    rxn_var = nra_model.reactions.get_by_id(rxn)\n",
    "    try:\n",
    "        vwt = reference_sample_WT[rxn]\n",
    "    except:\n",
    "        vwt = reference_sample_WT[rxn_var.reverse_id]\n",
    "    vmut = np.abs(tfa_sample[rxn_var.id] - tfa_sample[rxn_var.reverse_id])\n",
    "    df_effect_const.loc[rxn, 'ln_vWT_vMUT'] = np.log(vwt / vmut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the enzymes by susbsystems too and make a grouped df\n",
    "df_effect_sum = df_effect.groupby('Subsystem').sum()\n",
    "df_effect_grouped = pd.DataFrame()\n",
    "for enz in df_effect_sum.columns:\n",
    "    sub = nra_model.reactions.get_by_id(enz).subsystem\n",
    "    effect = df_effect_sum.loc[:, enz]\n",
    "    if sub not in df_effect_grouped.columns:\n",
    "        df_effect_grouped[sub] = effect\n",
    "    else:\n",
    "        df_effect_grouped[sub] += effect\n",
    "\n",
    "# Make sure the columns have the same order as the index of the df_effect_grouped\n",
    "df_effect_grouped = df_effect_grouped.reindex(sorted(df_effect_grouped.columns), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the subsystems that are in core_ss\n",
    "df_effect_grouped_core = df_effect_grouped.loc[:, df_effect_grouped.columns.isin(core_ss)]\n",
    "\n",
    "# Make sure the index sort is the same as the columns\n",
    "df_effect_grouped_core = df_effect_grouped_core.reindex(sorted(df_effect_grouped_core.index), axis=0)\n",
    "df_effect_grouped_core = df_effect_grouped_core.reindex(sorted(df_effect_grouped_core.columns), axis=1)\n",
    "\n",
    "# Replace some names\n",
    "df_effect_grouped_core = df_effect_grouped_core.rename(index={\n",
    "    'ETC_Rxns': 'Oxidative phosphorylation',\n",
    "    'Glycine, serine, alanine, and threonine metabolism': 'Gly/Ser/Ala/Thr metabolism',\n",
    "    'Arginine and proline metabolism': 'Arg/Pro metabolism'\n",
    "})\n",
    "\n",
    "df_effect_grouped_core = df_effect_grouped_core.rename(columns={\n",
    "    'ETC_Rxns': 'Oxidative phosphorylation',\n",
    "    'Glycine, serine, alanine, and threonine metabolism': 'Gly/Ser/Ala/Thr metabolism',\n",
    "    'Arginine and proline metabolism': 'Arg/Pro metabolism'\n",
    "})\n",
    "\n",
    "# Sort the index and columns based on \n",
    "order = [\n",
    "    'Gly/Ser/Ala/Thr metabolism', 'Arg/Pro metabolism', 'Glutamate metabolism',\n",
    "    'Glycolysis/gluconeogenesis', 'Pentose phosphate pathway', 'Citric acid cycle',\n",
    "    'Urea cycle', 'Pyrimidine synthesis', 'Purine synthesis',\n",
    "    'NAD metabolism', 'ROS detoxification', 'Oxidative phosphorylation'\n",
    "]\n",
    "\n",
    "df_effect_grouped_core = df_effect_grouped_core.reindex(index=order, columns=order)\n",
    "\n",
    "# Set color scale limits (change these values as needed)\n",
    "color_limit = 50\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Clamp values to [-color_limit, color_limit] range for color mapping\n",
    "df_effect_clamped = df_effect_grouped_core.clip(lower=-color_limit, upper=color_limit)\n",
    "\n",
    "# Draw heatmap with clamped values\n",
    "sns.heatmap(\n",
    "    df_effect_clamped,\n",
    "    annot=False,\n",
    "    cmap='RdBu_r',\n",
    "    center=0,\n",
    "    vmin=-color_limit,\n",
    "    vmax=color_limit,\n",
    "    fmt='.2f',\n",
    "    linewidths=0.5,\n",
    "    square=True,\n",
    "    cbar=False,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Create small horizontal colorbar (1/5th width, thicker height) at top-right\n",
    "cax = inset_axes(\n",
    "    ax,\n",
    "    width=\"20%\",         \n",
    "    height=\"5%\",        \n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(0, 0, 1, 1.1),\n",
    "    bbox_transform=ax.transAxes,\n",
    "    borderpad=0\n",
    ")\n",
    "\n",
    "# Colorbar content - use clamped range\n",
    "vmin = -color_limit\n",
    "vmax = color_limit\n",
    "norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "sm = plt.cm.ScalarMappable(cmap='RdBu_r', norm=norm)\n",
    "cb = fig.colorbar(sm, cax=cax, orientation='horizontal')\n",
    "\n",
    "# Set custom tick values and labels\n",
    "tick_values = [-color_limit, 0, color_limit]\n",
    "tick_labels = [f' < -{color_limit}', '0', f' > {color_limit}']\n",
    "cb.set_ticks(tick_values)\n",
    "cb.set_ticklabels(tick_labels)\n",
    "cb.ax.tick_params(labelsize=8, direction='out')\n",
    "cax.xaxis.set_ticks_position(\"top\")\n",
    "cax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "# Axis labels and ticks\n",
    "# ax.set_xlabel('', fontsize=8)\n",
    "ax.set_ylabel('Affected Pathway', fontsize=15)\n",
    "ax.set_xlabel('Enzymes grouped according to their pathway', fontsize=15)\n",
    "ax.tick_params(axis='y', labelsize=12, rotation=0)\n",
    "\n",
    "# Apply ha='right' for x-axis tick labels\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_ha('right')\n",
    "    label.set_rotation(45)\n",
    "    label.set_fontsize(12)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Figure 5B, 5C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 1) Publication-grade font & style\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial'],\n",
    "    'font.size': 11,\n",
    "    'pdf.fonttype': 42,\n",
    "    'svg.fonttype': 'none'\n",
    "})\n",
    "sns.reset_defaults()\n",
    "sns.set_style('white')\n",
    "\n",
    "# 2) Define custom colors for positive/negative bars\n",
    "positive_color = '#228B22'  # ForestGreen\n",
    "negative_color = '#B22222'  # Firebrick\n",
    "\n",
    "# 3) Subsystems and enzymes\n",
    "subsystems = ['Glycolysis/gluconeogenesis', 'Pyrimidine synthesis']\n",
    "enzymes = df_effect_grouped_core.columns\n",
    "\n",
    "# 4) Prepare data matrix\n",
    "data = df_effect_grouped_core.loc[subsystems].values\n",
    "\n",
    "# 5) Loop over each subsystem and make its own figure\n",
    "for sub, vals in zip(subsystems, data):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), sharey=False)  # half the width\n",
    "    # assign colors\n",
    "    colors = [positive_color if v >= 0 else negative_color for v in vals]\n",
    "    y = np.arange(len(enzymes))\n",
    "\n",
    "    # plot horizontal bars\n",
    "    ax.barh(y, vals, height=0.6, color=colors, edgecolor='black', linewidth=1)\n",
    "\n",
    "    # zero line\n",
    "    ax.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "\n",
    "    # labels & title\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(enzymes, rotation=0, ha='right', fontsize=12)\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.set_title(sub, fontsize=18)\n",
    "    ax.set_ylabel('Effects of enzymes grouped by metabolic pathway', fontsize=14, labelpad=10)\n",
    "\n",
    "    # x-label only on the first plot\n",
    "    if sub == subsystems[0]:\n",
    "        ax.set_xlabel('Effect on pathway', fontsize=14, labelpad=10)\n",
    "    else:\n",
    "        # slightly extend lower limit on pyrimidine panel\n",
    "        x_min, x_max = ax.get_xlim()\n",
    "        ax.set_xlim(-2, x_max)\n",
    "        ax.set_xlabel('Effect on pathway', fontsize=14, labelpad=10)\n",
    "\n",
    "    sns.despine(ax=ax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save each separately\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Figure 5D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the essential enzymes txt file\n",
    "with open(path_to_essential_enzymes, 'r') as f:\n",
    "    essential_enzymes_list = [fline.strip() for fline in f.readlines()]\n",
    "\n",
    "# Load the reference solution\n",
    "sol = pd.read_csv(path_to_solutions.format('250'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in a dataframe the enzyme name if it is up or down regulated and the subsystem it belongs to\n",
    "essential_enzymes = pd.DataFrame(columns=['Enzyme', 'Subsystem', 'Regulation'])\n",
    "for enz in essential_enzymes_list:\n",
    "    var_up = sol.loc['EUU_' + enz].values[0]\n",
    "    var_down = sol.loc['EDU_' + enz].values[0]\n",
    "    if np.isclose(var_up, 1.0):\n",
    "        regulation = 'up'\n",
    "    elif np.isclose(var_down, 1.0):\n",
    "        regulation = 'down'\n",
    "    else:\n",
    "        raise ValueError(f\"Enzyme {enz} is not up or down regulated\")\n",
    "\n",
    "    rxn = nra_model.reactions.get_by_id(enz)\n",
    "    sub = rxn.subsystem\n",
    "    essential_enzymes = essential_enzymes.append({'Enzyme': enz, 'Subsystem': sub, 'Regulation': regulation}, ignore_index=True)\n",
    "\n",
    "# Set the index to the enzyme name\n",
    "essential_enzymes.set_index('Enzyme', inplace=True)\n",
    "\n",
    "# Print how many enzymes are up or down regulated \n",
    "print(f\"Number of down regulated enzymes: {len(essential_enzymes[essential_enzymes['Regulation'] == 'down'])}\")\n",
    "print(f\"Number of up regulated enzymes: {len(essential_enzymes[essential_enzymes['Regulation'] == 'up'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for high-impact journals\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Count number of up- and down-regulated enzymes per subsystem\n",
    "df = essential_enzymes.copy()\n",
    "\n",
    "# Rename the long subsystem\n",
    "df['Subsystem'] = df['Subsystem'].replace(\n",
    "    'Glycine, serine, alanine, and threonine metabolism',\n",
    "    'Gly/Se/rAla/Theo metabolism'\n",
    ")\n",
    "\n",
    "# Lump subsystems with fewer than 8 enzymes into \"Other\"\n",
    "subsystem_counts = df['Subsystem'].value_counts()\n",
    "rare_subsystems = subsystem_counts[subsystem_counts < 8].index\n",
    "df['Subsystem'] = df['Subsystem'].replace(rare_subsystems, 'Other')\n",
    "\n",
    "# Group and count\n",
    "count_df = df.groupby(['Subsystem', 'Regulation']).size().reset_index(name='Count')\n",
    "\n",
    "# Ensure 'Other' is at the end\n",
    "subsystem_order = [s for s in count_df['Subsystem'].unique() if s != 'Other']\n",
    "subsystem_order.sort()\n",
    "subsystem_order.append('Other')\n",
    "\n",
    "colors = ['#2E86AB', '#A23B72']  # Blue and burgundy\n",
    "\n",
    "# Calculate total essential enzymes per subsystem and sort\n",
    "totals = [\n",
    "    \"Gly/Ser/Ala/Thr metabolism\",\n",
    "    \"Arginine and proline metabolism\",\n",
    "    \"Glutamate metabolism\",\n",
    "    \"Glycolysis/gluconeogenesis\",\n",
    "    \"Pentose phosphate pathway\",\n",
    "    \"Citric acid cycle\",\n",
    "    \"Urea cycle\",\n",
    "    \"Pyrimidine synthesis\",\n",
    "    \"NAD metabolism\",\n",
    "    \"Other\"\n",
    "]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 6))  # taller than it is wide\n",
    "sns.barplot(\n",
    "    data=count_df,\n",
    "    y='Subsystem',\n",
    "    x='Count',\n",
    "    hue='Regulation',\n",
    "    order=totals,\n",
    "    palette=colors,\n",
    "    ax=ax,\n",
    "    edgecolor='black',\n",
    "    linewidth=1\n",
    ")\n",
    "\n",
    "# swap labels\n",
    "ax.set_ylabel('Metabolic Pathway', fontsize=12)\n",
    "ax.set_xlabel('Number of Essential Enzyme Changes', fontsize=12)\n",
    "\n",
    "# keep pathway names horizontal\n",
    "plt.yticks(rotation=0)\n",
    "ax.tick_params(axis='y', which='both', length=0)  # ensure no little stubs\n",
    "\n",
    "\n",
    "# move legend to the right, outside the axes\n",
    "legend = ax.legend(\n",
    "    loc='center',\n",
    "    bbox_to_anchor=(1.0, 1.0),\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "# rename legend entries\n",
    "legend.texts[0].set_text('Downregulated')\n",
    "legend.texts[1].set_text('Upregulated')\n",
    "\n",
    "# remove top and right spines\n",
    "sns.despine(ax=ax, top=True, right=True)\n",
    "\n",
    "# give a bit of extra right margin so the legend isn’t cut off\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "# Figure 5E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TFLink database\n",
    "tf_link = pd.read_csv(path_to_tflink_database, sep='\\t')\n",
    "\n",
    "from cobra.io.json import load_json_model # FBA type import\n",
    "recon = load_json_model(path_to_recon_model)\n",
    "\n",
    "# Load gene to UNIPROT mapping\n",
    "gene_uniprot_mapping = pd.read_csv(path_to_gene_to_uniprot_mapping, sep='\\t')\n",
    "\n",
    "# The first column should be a string\n",
    "gene_uniprot_mapping.iloc[:, 0] = gene_uniprot_mapping.iloc[:, 0].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "brca1_total = tf_link[tf_link['Name.TF']=='BRCA1']\n",
    "\n",
    "# Find which genes from recon3d are targeted by BRCA1\n",
    "genes_identified = []\n",
    "for ll in gene_uniprot_mapping.index:\n",
    "    ncbi = gene_uniprot_mapping.loc[ll,'gene_number'].split('.')[0]\n",
    "    if str(ncbi) in tf_link.loc[:,'NCBI.GeneID.Target'].values:\n",
    "        row = tf_link[tf_link.loc[:,'NCBI.GeneID.Target'] == str(ncbi)]\n",
    "        print(row)\n",
    "        genes_identified.append(row)\n",
    "\n",
    "# Make into a datframe\n",
    "genes_identified = pd.concat(genes_identified, ignore_index=True)\n",
    "genes_identified = genes_identified.drop_duplicates(ignore_index=True)\n",
    "\n",
    "# Now we go from those TFs as targets to BRCA1 as a TF\n",
    "tfs_identified = []\n",
    "for ll in genes_identified.index:\n",
    "    tf_name = genes_identified.loc[ll,'Name.TF']\n",
    "    if tf_name in brca1_total.loc[:,'Name.TF'].values:\n",
    "        row = brca1_total[brca1_total.loc[:,'Name.TF'] == tf_name]\n",
    "        print(row)\n",
    "        tfs_identified.append(row)\n",
    "\n",
    "# Make into a datframe\n",
    "tfs_identified = pd.concat(tfs_identified, ignore_index=True)\n",
    "tfs_identified = tfs_identified.drop_duplicates(ignore_index=True)\n",
    "\n",
    "# Go back to genes through the TFS identified in tfs_identified\n",
    "brca1_specific_genes = []\n",
    "for ll in tfs_identified.index:\n",
    "    tf_name = tfs_identified.loc[ll,'Name.Target']\n",
    "    if tf_name in genes_identified.loc[:,'Name.TF'].values:\n",
    "        row = genes_identified[genes_identified.loc[:,'Name.TF'] == tf_name]\n",
    "        print(row)\n",
    "        brca1_specific_genes.append(row)\n",
    "\n",
    "# Make into a datframe\n",
    "brca1_specific_genes = pd.concat(brca1_specific_genes, ignore_index=True)\n",
    "brca1_specific_genes = brca1_specific_genes.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "enz = []\n",
    "for i in recon.genes:\n",
    "    name = i.id.split('_')[0]\n",
    "    if name in brca1_specific_genes.loc[:,'NCBI.GeneID.Target'].values:\n",
    "        print(name)\n",
    "\n",
    "        for rxn in i.reactions:\n",
    "            if rxn.id not in enz:\n",
    "                enz.append(rxn.id)\n",
    "                print(rxn.id)\n",
    "print(f'Total number of reactions associated with BRCA1: {len(enz)}')\n",
    "\n",
    "# Do the same for the small model\n",
    "enz_small = []\n",
    "for i in nra_model.genes:\n",
    "    name = i.id.split('.',1)[0]\n",
    "    if name in brca1_specific_genes.loc[:,'NCBI.GeneID.Target'].values:\n",
    "        print(name)\n",
    "\n",
    "        for rxn in i.reactions:\n",
    "            if rxn.id not in enz_small:\n",
    "                enz_small.append(rxn.id)\n",
    "                print(rxn.id)\n",
    "print(f'Total number of reactions associated with BRCA1 in the small model: {len(enz_small)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each essential enzyme find the genes ascosiated with it\n",
    "essential_enzymes['genes'] = pd.Series(dtype=object) # Initialize with object dtype\n",
    "essential_enzymes['uniprot_genes'] = pd.Series(dtype=object) # Initialize with object dtype\n",
    "essential_enzymes['hugo_genes'] = pd.Series(dtype=object) # Initialize with object dtype\n",
    "\n",
    "# Iterate through each essential enzyme (reaction ID)\n",
    "for enz in essential_enzymes.index:\n",
    "    rxn = nra_model.reactions.get_by_id(enz)\n",
    "    genes = [g.id for g in rxn.genes]\n",
    "\n",
    "    if genes:\n",
    "        # Join multiple gene IDs with ';'\n",
    "        essential_enzymes.at[enz, 'genes'] = ';'.join(genes)\n",
    "        # Find the corresponding uniprot IDs\n",
    "        uniprot_ids = []\n",
    "        for gene in genes:\n",
    "            if gene in gene_uniprot_mapping['gene_number'].values:\n",
    "                uniprot_id = gene_uniprot_mapping.loc[gene_uniprot_mapping['gene_number'] == gene, 'uniprot_gname'].values[0]\n",
    "                if uniprot_id not in uniprot_ids and not pd.isna(uniprot_id):\n",
    "                    uniprot_ids.append(uniprot_id)\n",
    "        # Join multiple uniprot IDs with ';'\n",
    "        if uniprot_ids:\n",
    "            essential_enzymes.at[enz, 'uniprot_genes'] = ';'.join(uniprot_ids)\n",
    "        else:\n",
    "            # Keep as NaN if no uniprot IDs are found\n",
    "            essential_enzymes.at[enz, 'uniprot_genes'] = np.nan\n",
    "\n",
    "        # Find the corresponding HUGO gene names\n",
    "        hugo_genes = []\n",
    "        for gene in genes:\n",
    "            if gene in gene_uniprot_mapping['gene_number'].values:\n",
    "                hugo_id = gene_uniprot_mapping.loc[gene_uniprot_mapping['gene_number'] == gene, 'symbol'].values[0]\n",
    "                if hugo_id not in hugo_genes and not pd.isna(hugo_id):\n",
    "                    hugo_genes.append(hugo_id)\n",
    "        # Join multiple HUGO gene names with ';'\n",
    "        if hugo_genes:\n",
    "            essential_enzymes.at[enz, 'hugo_genes'] = ';'.join(hugo_genes)\n",
    "        else:\n",
    "            # Keep as NaN if no HUGO gene names are found\n",
    "            essential_enzymes.at[enz, 'hugo_genes'] = np.nan\n",
    "    else:\n",
    "        # Keep as NaN if no genes are associated\n",
    "        essential_enzymes.at[enz, 'genes'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if TFLink returns more TF hits for the essential enzymes\n",
    "essential_enzymes['TF_link'] = pd.Series(dtype=object) # Initialize with object dtype\n",
    "\n",
    "for enz in essential_enzymes.index:\n",
    "    uniprot_ids = essential_enzymes.loc[enz, 'uniprot_genes']\n",
    "    if not pd.isna(uniprot_ids):\n",
    "        uniprot_ids_split = uniprot_ids.split(';')\n",
    "        tf_hits = []\n",
    "        for uniprot_id in uniprot_ids_split:\n",
    "            tf_matches = tf_link.loc[tf_link['UniprotID.Target'] == uniprot_id, 'Name.TF']\n",
    "            if not tf_matches.empty:\n",
    "                tf_hits.extend(tf_matches.unique())\n",
    "        if tf_hits:\n",
    "            essential_enzymes.at[enz, 'TF_link'] = ';'.join(tf_hits)\n",
    "        else:\n",
    "            essential_enzymes.at[enz, 'TF_link'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many unique genes are there\n",
    "gene_list = []\n",
    "for i in essential_enzymes['genes'].dropna():\n",
    "    genes = i.split(';')\n",
    "    for gene in genes:\n",
    "        gene_list.append(gene)\n",
    "print(f\"{essential_enzymes.genes.notna().sum()}/{len(essential_enzymes)} essential enzymes have genes associated with them\")\n",
    "print(f\"Number of genes: {len(gene_list)}\")\n",
    "print(f\"Number of unique genes: {len(set(gene_list))}\\n\")\n",
    "\n",
    "# Find how many unique TFs are there for TF_link\n",
    "tfs_list_tf_link = []\n",
    "for i in essential_enzymes['TF_link'].dropna():\n",
    "    tfs = i.split(';')\n",
    "    for tf in tfs:\n",
    "        tfs_list_tf_link.append(tf)\n",
    "print(f\"{essential_enzymes.TF_link.notna().sum()}/{len(essential_enzymes)} essential enzymes have TF_link TFs associated with them\")\n",
    "print(f\"Number of TFs: {len(tfs_list_tf_link)}\")\n",
    "print(f\"Number of unique TFs: {len(set(tfs_list_tf_link))}\\n\")\n",
    "\n",
    "# Find the unique genes that are associated with the TF_link TFs\n",
    "genes_tfs_tf_link = []\n",
    "for i in essential_enzymes[essential_enzymes.TF_link.notna()].genes:\n",
    "    genes = i.split(';')\n",
    "    for gene in genes:\n",
    "        genes_tfs_tf_link.append(gene)\n",
    "print(f\"Number of genes associated with TF_link TFs: {len(genes_tfs_tf_link)}\")\n",
    "print(f\"Number of unique genes associated with TF_link TFs: {len(set(genes_tfs_tf_link))}\\n\")\n",
    "print('------------------------------------------------------')\n",
    "\n",
    "print(f'In total {essential_enzymes.TF_link.notna().sum()}/{len(essential_enzymes)} essential enzymes are connected to {len(set(genes_tfs_tf_link))} unique genes and are regulated by {len(set(tfs_list_tf_link))} unique TFs (TF_link)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "essential_enzymes.to_csv(path_to_essential_enzymes_to_TFs_mapping)\n",
    "df = pd.read_csv(path_to_essential_enzymes_to_TFs_mapping)\n",
    "\n",
    "# Change the Subsystems ETC_Rxns to Electron transport chain\n",
    "df['Subsystem'] = df['Subsystem'].replace('ETC_Rxns', 'Electron transport chain')\n",
    "# Drop rows missing TF or gene\n",
    "df_filtered = df.dropna(subset=['TF_link', 'hugo_genes'])\n",
    "\n",
    "# Split semicolon-separated values\n",
    "df_filtered['hugo_genes'] = df_filtered['hugo_genes'].astype(str).str.split(';')\n",
    "df_filtered['TF_link'] = df_filtered['TF_link'].astype(str).str.split(';')\n",
    "\n",
    "# Explode all combinations\n",
    "df_exploded = df_filtered.explode('hugo_genes').explode('TF_link')\n",
    "df_exploded['hugo_genes'] = df_exploded['hugo_genes'].str.strip()\n",
    "df_exploded['TF_link'] = df_exploded['TF_link'].str.strip()\n",
    "\n",
    "# !!! IMPORTANT: Apply NADH2_u10mi merge before filtering to top TFs if we want this aggregated enzyme\n",
    "# to be considered in the overall flow calculation for top TFs or relevant enzymes.\n",
    "# If the merge is done later, the 'Enzyme' column for NADH2_u10mi might still be the original for earlier steps.\n",
    "# Let's keep it here as it was.\n",
    "df_exploded['hugo_genes'] = df_exploded.apply(\n",
    "    lambda row: 'NADH2_u10mi genes' if row['Enzyme'] == 'NADH2_u10mi' else row['hugo_genes'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter to top 5 most common TFs based on all original connections\n",
    "top_5_tfs_all_connections = df_exploded['TF_link'].value_counts().nlargest(5).index.tolist()\n",
    "top_5_tfs_all_connections = ['SP1', 'MYC', 'RELA', 'NFKB1', 'AR', 'HIF1A', 'STAT1', 'EGR1', 'TP53']  # Use the same top TFs as before\n",
    "df_top = df_exploded[df_exploded['TF_link'].isin(top_5_tfs_all_connections)].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "# Filter relevant columns and remove rows without Subsystem info\n",
    "df_top.dropna(subset=['Subsystem'], inplace=True)\n",
    "\n",
    "\n",
    "# --- REVISED LOGIC FOR ORDERING NODES BY FLOW ---\n",
    "\n",
    "# 1. Prepare link dataframes with calculated 'value' for sorting\n",
    "#    These are the actual links that will be drawn, so their 'value' is what we sort by.\n",
    "\n",
    "# TF -> Enzyme links\n",
    "tf_enzyme_flows = df_top.groupby(['TF_link', 'Enzyme']).size().reset_index(name='value')\n",
    "\n",
    "# Enzyme -> Subsystem links\n",
    "enzyme_subsystem_flows = df_top.groupby(['Enzyme', 'Subsystem']).size().reset_index(name='value')\n",
    "\n",
    "# 2. Calculate total 'flow' for each node type (what's coming into it or leaving it)\n",
    "\n",
    "# TFs: Sort by their total outgoing flow to enzymes (which is their primary contribution)\n",
    "tf_outgoing_flow = tf_enzyme_flows.groupby('TF_link')['value'].sum().sort_values(ascending=False)\n",
    "sorted_tfs = tf_outgoing_flow.index.tolist()\n",
    "\n",
    "# Enzymes: Sort by their total incoming flow from TFs.\n",
    "# This aligns with \"inputs in each layer ... biggest inflow to smallest\".\n",
    "# NADH2_u10mi is already handled in df_exploded before this step.\n",
    "enzyme_inflow_sum = tf_enzyme_flows.groupby('Enzyme')['value'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Ensure only enzymes present in the filtered df_top are considered\n",
    "relevant_enzymes_in_df_top = df_top['Enzyme'].unique().tolist()\n",
    "# Filter enzyme_inflow_sum to include only relevant enzymes\n",
    "sorted_enzymes = [e for e in enzyme_inflow_sum.index.tolist() if e in relevant_enzymes_in_df_top]\n",
    "\n",
    "\n",
    "# Subsystems: Sort by their total incoming flow from Enzymes.\n",
    "subsystem_inflow_sum = enzyme_subsystem_flows.groupby('Subsystem')['value'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Ensure only subsystems present in the filtered df_top are considered\n",
    "relevant_subsystems_in_df_top = df_top['Subsystem'].unique().tolist()\n",
    "# Filter subsystem_inflow_sum to include only relevant subsystems\n",
    "sorted_subsystems = [s for s in subsystem_inflow_sum.index.tolist() if s in relevant_subsystems_in_df_top]\n",
    "\n",
    "\n",
    "# 3. Combine all nodes in the desired order for Sankey\n",
    "# This order is CRITICAL for Plotly's rendering.\n",
    "nodes = sorted_tfs + sorted_enzymes + sorted_subsystems\n",
    "node_indices = {name: i for i, name in enumerate(nodes)}\n",
    "\n",
    "# --- END REVISED LOGIC ---\n",
    "\n",
    "# Build Sankey links using the prepared flow dataframes\n",
    "source, target, value = [], [], []\n",
    "\n",
    "# TF → Enzyme links\n",
    "for _, row in tf_enzyme_flows.iterrows():\n",
    "    # Only add links if both source and target nodes exist in our final `nodes` list\n",
    "    if row['TF_link'] in node_indices and row['Enzyme'] in node_indices:\n",
    "        source.append(node_indices[row['TF_link']])\n",
    "        target.append(node_indices[row['Enzyme']])\n",
    "        value.append(row['value'])\n",
    "\n",
    "# Enzyme → Subsystem links\n",
    "for _, row in enzyme_subsystem_flows.iterrows():\n",
    "    # Only add links if both source and target nodes exist in our final `nodes` list\n",
    "    if row['Enzyme'] in node_indices and row['Subsystem'] in node_indices:\n",
    "        source.append(node_indices[row['Enzyme']])\n",
    "        target.append(node_indices[row['Subsystem']])\n",
    "        value.append(row['value'])\n",
    "\n",
    "\n",
    "# Node colors (using the new sorted lists for checks)\n",
    "node_colors = []\n",
    "for node in nodes:\n",
    "    if node in sorted_tfs:\n",
    "        node_colors.append('rgba(255, 127, 14, 0.8)')  # TF = orange\n",
    "    elif node in sorted_enzymes:\n",
    "        node_colors.append('rgba(44, 160, 44, 0.8)') # Enzyme = green\n",
    "    else: # Subsystem\n",
    "        node_colors.append('rgba(31, 119, 180, 0.8)') # Subsystem = blue\n",
    "\n",
    "# Link colors by source type (using the new sorted lists for checks)\n",
    "link_colors = []\n",
    "for s_idx in source: # s_idx is the index in the 'nodes' list\n",
    "    if nodes[s_idx] in sorted_tfs:\n",
    "        link_colors.append('rgba(255, 127, 14, 0.3)')  # TF→Enzyme (orange-ish)\n",
    "    elif nodes[s_idx] in sorted_enzymes:\n",
    "        link_colors.append('rgba(44, 160, 44, 0.3)')   # Enzyme→Subsystem (green-ish)\n",
    "\n",
    "# Create Sankey plot\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    textfont=dict(size=21, family='Arial, sans-serif'),  # <-- add this\n",
    "    node=dict(\n",
    "        pad=20,\n",
    "        thickness=25,\n",
    "        line=dict(color=\"black\", width=0.8),\n",
    "        label=nodes, # This is the crucial part for ordering\n",
    "        color=node_colors,\n",
    "        hovertemplate='<b>%{label}</b><br>Total flow: %{value}<extra></extra>'\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=source,\n",
    "        target=target,\n",
    "        value=value,\n",
    "        color=link_colors,\n",
    "        hovertemplate='<b>%{source.label}</b> → <b>%{target.label}</b><br>Flow: %{value}<extra></extra>'\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"\",\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font': {'size': 16, 'family': 'Arial, sans-serif'}\n",
    "    },\n",
    "    font=dict(size=16, family='Arial, sans-serif'),\n",
    "    plot_bgcolor='rgba(0,0,0,0)',    # transparent plotting area\n",
    "    paper_bgcolor='rgba(0,0,0,0)',   # transparent paper/background\n",
    "    width=2400,\n",
    "    height=1200,\n",
    "    margin=dict(l=50, r=50, t=80, b=50)\n",
    ")\n",
    "\n",
    "# TFs title in orange\n",
    "fig.add_annotation(dict(\n",
    "    x=0,\n",
    "    y=0.95,\n",
    "    xref='paper',\n",
    "    yref='paper',\n",
    "    text='TFs',\n",
    "    showarrow=False,\n",
    "    font=dict(size=28, family='Arial, sans-serif',\n",
    "              color='rgba(255,127,14,1)')  # orange\n",
    "))\n",
    "\n",
    "# Enzymes title in green\n",
    "fig.add_annotation(dict(\n",
    "    x=0.5,\n",
    "    y=1.03,\n",
    "    xref='paper',\n",
    "    yref='paper',\n",
    "    text='Enzymes',\n",
    "    showarrow=False,\n",
    "    font=dict(size=28, family='Arial, sans-serif',\n",
    "              color='rgba(44,160,44,1)')   # green\n",
    "))\n",
    "\n",
    "# Pathways title in blue\n",
    "fig.add_annotation(dict(\n",
    "    x=1.015,\n",
    "    y=1.03,\n",
    "    xref='paper',\n",
    "    yref='paper',\n",
    "    text='Pathways',\n",
    "    showarrow=False,\n",
    "    font=dict(size=28, family='Arial, sans-serif',\n",
    "              color='rgba(31,119,180,1)')  # blue\n",
    "))\n",
    "\n",
    "# # Save the figure to pdf\n",
    "# fig.write_image(\"sankey_plot.png\", format=\"png\", scale=3)\n",
    "\n",
    "# Save the figure as pdf\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
